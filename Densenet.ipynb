{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22658135-d6bc-436e-811c-81637740db95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 13:45:46.222044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731264346.626705  223236 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731264346.693423  223236 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-10 13:45:47.581458: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setup and Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2993c6a-9d5f-46d4-9520-214f49632ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221946ae-d832-46d5-8fed-888cad7c244e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define image size and paths\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Step 2: Load Image from URL and Visualize\n",
    "# Function to download the image from the URL\n",
    "def download_image_from_url(url, save_path):\n",
    "    urllib.request.urlretrieve(url, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383c7927-51e6-4c94-84ca-ff13e70778e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://dl.dropboxusercontent.com/scl/fi/vmox93cwsx2vzrish3l63/land_ls_model_data_four.zip?rlkey=6uykz7bb0aoqbl8hgfkpt1t4f&dl=0?raw=1\n",
      "\u001b[1m1483731620/1483731620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "dataset_url = \"https://dl.dropboxusercontent.com/scl/fi/vmox93cwsx2vzrish3l63/land_ls_model_data_four.zip?rlkey=6uykz7bb0aoqbl8hgfkpt1t4f&dl=0?raw=1\"\n",
    "\n",
    "# Download and unzip the dataset\n",
    "dataset_path = tf.keras.utils.get_file('land_ls_model_data_four.zip', origin=dataset_url, extract=True)\n",
    "extracted_dir = os.path.join(os.path.dirname(dataset_path), 'land_ls_model_data_four')  # Adjust path as necessary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fad2370-1366-4843-a9ed-023bba85b184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/rrm3nh/.keras/datasets/land_ls_model_data_four_extracted'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(extracted_dir)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Extract the ZIP file\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m      8\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(extracted_dir)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Check if the extraction was successful\u001b[39;00m\n",
      "File \u001b[0;32m/apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/zipfile.py:1284\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/home/rrm3nh/.keras/datasets/land_ls_model_data_four_extracted'"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "extracted_dir = os.path.join(os.path.dirname(dataset_path), 'land_ls_model_data_four')\n",
    "if not os.path.exists(extracted_dir):\n",
    "    os.makedirs(extracted_dir)\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "\n",
    "# Check if the extraction was successful\n",
    "if not os.path.exists(extracted_dir):\n",
    "    print(f\"Extraction failed or directory does not exist: {extracted_dir}\")\n",
    "else:\n",
    "    print(f\"Dataset extracted successfully to: {extracted_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dddcf07-7b1f-459f-bdf1-11c97d58a0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "extracted_dir = '/home/mjp2da/.keras/datasets/land_ls_model_data_four'\n",
    "\n",
    "# Create a 'train' directory if it doesn't exist\n",
    "train_dir = os.path.join(extracted_dir, 'train')\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "\n",
    "# Move 'landslide' and 'non_landslide' directories into the 'train' folder\n",
    "landslide_dir = os.path.join(extracted_dir, 'landslide')\n",
    "non_landslide_dir = os.path.join(extracted_dir, 'non_landslide')\n",
    "\n",
    "# Move the directories into the 'train' directory\n",
    "shutil.move(landslide_dir, os.path.join(train_dir, 'landslide'))\n",
    "shutil.move(non_landslide_dir, os.path.join(train_dir, 'non_landslide'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6de2ac-f151-47e2-a99d-528f73f93109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# URLs for sample images\n",
    "landslide_img_one_url = \"https://dl.dropboxusercontent.com/scl/fi/viovy9pcma2y6hq58ntns/NASA_GoogE_14445.jpg?rlkey=ltitymrzuarrxxogge32c1kbi&dl=0?raw=1\"\n",
    "landslide_img_two_url = \"https://dl.dropboxusercontent.com/scl/fi/7x41si7aih0bjh1py2phy/NASA_GoogE_14445_NonSlide.jpg?rlkey=3ll97pdrjwr9b10rcvineeynm&dl=0?raw=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8185200a-b7a4-477d-aaf4-27222872c3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download images\n",
    "landslide_img_one_path = tf.keras.utils.get_file('NASA_GoogE_14445', origin=landslide_img_one_url)\n",
    "landslide_img_two_path = tf.keras.utils.get_file('NASA_GoogE_14445_NonSlide', origin=landslide_img_two_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc83c2b-05b2-438f-95d1-fb79a9699641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize_show(image_path):\n",
    "    img = tf.keras.utils.load_img(image_path, target_size=(300, 300))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Prediction helper function\n",
    "def predict_landslide_image(image_path, model):\n",
    "    img = tf.keras.utils.load_img(image_path, target_size=(img_height, img_width))\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = predictions[0][0]\n",
    "\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(\"landslide\" if score > 0.5 else \"non-landslide\", 100 * score if score > 0.5 else 100 * (1 - score))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73beb5f-ba66-4639-9cfa-e1ce4acae273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize images\n",
    "PIL.Image.open(landslide_img_one_path)\n",
    "resize_show(landslide_img_one_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b6fd6-fa96-403f-a79f-f3a8b50a4aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PIL.Image.open(landslide_img_two_path)\n",
    "resize_show(landslide_img_two_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65cedb-ac19-4acc-bc21-0062af8aebe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: Model Setup\n",
    "\n",
    "# Load DenseNet121 as base model\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "base_model.trainable = False  # Freeze the base layers\n",
    "\n",
    "# Add custom layers on top\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)  # Add dropout for regularization\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c012110f-812c-49aa-a4d8-3250514e5630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the final model\n",
    "landslide_model_DenseNet = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66bb6b5-c9b6-461a-9214-fab4d732ee4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "landslide_model_DenseNet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7002309-f430-4013-8d55-0585e6de1fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,               # Normalize pixel values between 0 and 1\n",
    "    shear_range=0.2,              # Randomly shear images\n",
    "    zoom_range=0.2,               # Randomly zoom images\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Randomly flip images horizontally\n",
    ")\n",
    "\n",
    "# Setup for training data - Assume that you have a directory with images classified into 'landslides' and 'non-landslides'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,          # Path to your training data\n",
    "    target_size=(img_height, img_width),  # Resize images to the required input size for DenseNet\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'            # Binary classification: landslide vs non-landslide\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd39f2-2f53-482d-9691-7ed31f7fb8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,                      # Path to your training data\n",
    "    target_size=(img_height, img_width),  # Resize images\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',            # Binary classification: landslide vs non-landslide\n",
    "    subset='validation'             # Specify subset for validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1175e2-3185-446b-a566-0c6dbbb27e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Train the Model\n",
    "epochs = 10\n",
    "history = landslide_model_DenseNet.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8a2c8-959f-4d45-8b99-c4e1b5f8001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Plot Training and Validation Accuracy and Loss\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c23bf9-398a-4c83-9024-54bc49d12a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca9d61-3bb4-4fa7-a242-016c513465ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05153c-fda6-407c-8528-4c04d1894ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "train_dir = os.path.join(extracted_dir, 'train')\n",
    "test_dir = os.path.join(extracted_dir, 'test')\n",
    "\n",
    "# Create test directory and subdirectories if they don't exist\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "for class_name in ['landslide', 'non_landslide']:\n",
    "    class_train_dir = os.path.join(train_dir, class_name)\n",
    "    class_test_dir = os.path.join(test_dir, class_name)\n",
    "    if not os.path.exists(class_test_dir):\n",
    "        os.makedirs(class_test_dir)\n",
    "    \n",
    "    # Move 20% of the images to the test directory\n",
    "    images = os.listdir(class_train_dir)\n",
    "    num_test_images = int(0.2 * len(images))\n",
    "    test_images = random.sample(images, num_test_images)\n",
    "    \n",
    "    for image_name in test_images:\n",
    "        src_path = os.path.join(class_train_dir, image_name)\n",
    "        dst_path = os.path.join(class_test_dir, image_name)\n",
    "        shutil.move(src_path, dst_path)\n",
    "\n",
    "print(\"Test dataset created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ef581-b7ad-4428-b83a-8de8ba120672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the path to your test data directory\n",
    "test_dir = os.path.join(extracted_dir, 'test')\n",
    "\n",
    "# Initialize ImageDataGenerator for the test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Only rescaling for test data\n",
    "\n",
    "# Set up the test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',    # Ensure binary classification mode\n",
    "    shuffle=False           # Do not shuffle for evaluation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c45eb-c213-42e7-9d0f-fce6e537b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the Model on Test Data\n",
    "test_loss, test_accuracy = landslide_model_DenseNet.evaluate(test_generator)\n",
    "print(f'Test accuracy: {test_accuracy:.2f}, Test loss: {test_loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3b39d3-ec94-4bda-93b3-bb7e91b44547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Single Image Prediction Helper Functions\n",
    "\n",
    "# Prediction helper function\n",
    "def predict_landslide_image(image_path, model):\n",
    "    img = tf.keras.utils.load_img(image_path, target_size=(img_height, img_width))\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = predictions[0][0]\n",
    "\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(\"landslide\" if score > 0.5 else \"non-landslide\", 100 * score if score > 0.5 else 100 * (1 - score))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877e673-a594-4a35-b9f7-115098ae8226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and display helper function\n",
    "def resize_show(image_path):\n",
    "    img = tf.keras.utils.load_img(image_path, target_size=(300, 300))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Testing with sample images\n",
    "sample_landslide_img = landslide_img_one_path\n",
    "sample_non_landslide_img = landslide_img_two_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6afe180-fc15-43a8-8c27-c3c2fdf660ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and Predict for Landslide Image\n",
    "print(\"Landslide Image Prediction:\")\n",
    "resize_show(sample_landslide_img)\n",
    "predict_landslide_image(sample_landslide_img, landslide_model_DenseNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc7aee-ca48-44a8-b57f-7755d33cb4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display and Predict for Non-Landslide Image\n",
    "print(\"Non-Landslide Image Prediction:\")\n",
    "resize_show(sample_non_landslide_img)\n",
    "predict_landslide_image(sample_non_landslide_img, landslide_model_DenseNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4ae790-6236-46c1-b6de-e0aa52c379a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
