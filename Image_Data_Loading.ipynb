{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c59b74d-5ae8-4dfd-9621-13bedfa28384",
   "metadata": {},
   "source": [
    "# Ariel/Sat. Landslide Data Loading\n",
    "The following notebook is a guide to load image data sets for model training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4145cd19-a710-41ef-9b12-d06596d5539f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers  ### Adding 'regularizers'\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eca8dfc-1612-421a-aa66-8538e3b32af0",
   "metadata": {},
   "source": [
    "#### Relevant Links:\n",
    "0. Trial Link just to test linkages: Please try.<br>\n",
    "https://www.dropbox.com/scl/fi/ryo0gocx5ibsttv0635jg/ls_model_data_two_v2.zip?rlkey=i6fg2du9osvc0h6hpcoul1xa1&dl=0  <br>\n",
    "\n",
    "1. ls_model_data_three.zip: Contains Training landslide images from Longxi River UAV and non-landslide images from DeepGlobe Land Cover Classification Dataset. 2000 Images\n",
    "Working on this - resizing to get the zip file much lower, to 1.5G.\n",
    "https://www.dropbox.com/scl/fi/hgz1prxm1kx14w5riy9du/ls_model_data_three.zip?rlkey=7cv22qxmmaeofr7jn6z7iayjy&dl=0\n",
    "\n",
    "2. ls_model_data_four: includes training images from Longxihe_UAV, Lombok, Moxitown (UAV-.2m) and Hokkaido. 3200 Images\n",
    "https://dl.dropboxusercontent.com/scl/fi/vmox93cwsx2vzrish3l63/land_ls_model_data_four.zip?rlkey=6uykz7bb0aoqbl8hgfkpt1t4f&dl=0\n",
    "\n",
    "3. Old Test Images (Google) <br>\n",
    "https://dl.dropboxusercontent.com/scl/fi/wbi8iuftwvwnflvjr15pv/test_googleimages_land.zip?rlkey=h2stfvt9ocltsog29l26wo1ls&dl=0?raw=1\n",
    "\n",
    "4. ls_model_data_five: includes 3304 Landslide and 3940 Non Landslide images. <br>\n",
    "https://dl.dropboxusercontent.com/scl/fi/mrsbiu74dh3h3i0j2xi8b/ls_model_data_five.zip?rlkey=in4z2twssi71adfi1exknm67w&dl=0?raw=1\n",
    "Images from:\n",
    "- https://huggingface.co/datasets/satellite-image-deep-learning/SODA-A/tree/main\n",
    "- https://www.kaggle.com/datasets/balraj98/deepglobe-land-cover-classification-dataset\n",
    "- And CAS: Longxihe_UAV, Lombok, Moxitown (UAV-.2m) and Hokkaido.\n",
    "\n",
    "5. New Test Set (Google) <br>\n",
    "https://dl.dropboxusercontent.com/scl/fi/nyv6xg7u0lj5uv5jtglto/test_google_images_landslide_three.zip?rlkey=b7xnjid2s7zvfjbp0oqtji084&dl=0?raw=1\n",
    "\n",
    "6. New Test Set for Train/Validation/Test of 2nd Model <br>\n",
    "https://dl.dropboxusercontent.com/s/0en4k86c1r1uzs0/test_google_images_landslides_four.zip?st=pdg6yhzj&dl=0?raw=1\n",
    "\n",
    "7. ls_model_data_six_combined_v2: Combination of images from #4 and the NASA Google Earth dataset. \n",
    "https://dl.dropboxusercontent.com/scl/fi/sy3duklriddl3fo668as8/ls_model_data_six_combined_v2.zip?rlkey=chgywsbsn3ny0m2vrllll8icx&dl=0?raw=1\n",
    "\n",
    "\n",
    "Notes per DropBox Requirements:\n",
    "- Add ?raw=1 to the end of the dropbox link in the full URL link as seen below. \n",
    "- replace dropbox.com in link with \"dl.dropboxusercontent.com\" as seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d58972-6ee6-4a1d-bbbd-3675da24c178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the path to the zip file\n",
    "dataset_url = \"https://dl.dropboxusercontent.com/scl/fi/mrsbiu74dh3h3i0j2xi8b/ls_model_data_five.zip?rlkey=in4z2twssi71adfi1exknm67w&dl=0?raw=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912fab0d-9e62-4753-b1e0-9a421d6bece0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file('ls_model_data_five.zip', origin=dataset_url, extract=True)\n",
    "data_dir = pathlib.Path(data_dir).with_suffix('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68570471-1318-4ab5-b296-8b80e7b0e324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d1f79-4821-4c5c-a263-bc8ebad506a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders = [folder for folder in data_dir.glob('*') if folder.is_dir()]\n",
    "print(\"Folders in the dataset directory:\")\n",
    "for folder in folders:\n",
    "    print(folder.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89002b-962e-4346-b1eb-f8c1c83ed125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drill into each subdirectory and list counts per folder\n",
    "for folder in folders:\n",
    "    print(f\"\\nContents of folder '{folder.name}':\")\n",
    "    # for subitem in folder.iterdir():\n",
    "    count = len(list(folder.glob('*.jpg')))\n",
    "    print(f\"{folder.name}: {count} .jpg images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4067705-3b64-48a8-9b87-854f8471976f",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1f00f-33ff-4b7f-9d75-043aee6ecb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resize and Printer Helper\n",
    "def resize_show(image_path):\n",
    "    img = tf.keras.utils.load_img(\n",
    "        image_path, target_size=(500,500)\n",
    "    )\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Optional: turn off the axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9585e7e-2ea0-48c0-a7b9-950434cd3543",
   "metadata": {},
   "source": [
    "### Review an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41633c1c-0265-444a-9429-2be9b587c2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "landslide_one = list(data_dir.glob('landslide/*'))\n",
    "# PIL.Image.open(str(landslide_one[50]))\n",
    "resize_show(landslide_one[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6fd92e-6485-4bdb-8380-6c71f034fcc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# landslide_one = list(data_dir.glob('landslide/*'))\n",
    "# PIL.Image.open(str(landslide_one[0]))\n",
    "\n",
    "non_landslide_img = list(data_dir.glob('non_landslide/*'))\n",
    "# PIL.Image.open(str(non_landslide_img[1]))\n",
    "resize_show(non_landslide_img[120])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67451619-543c-43d3-83d6-ff79bc06acda",
   "metadata": {},
   "source": [
    "## Separate Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acccbad-82d1-4ef4-99a2-9cf7d138c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.dropbox.com/scl/fi/nyv6xg7u0lj5uv5jtglto/test_google_images_landslide_three.zip?rlkey=b7xnjid2s7zvfjbp0oqtji084&dl=0\n",
    "# test_dataset_url = \"https://dl.dropboxusercontent.com/scl/fi/nyv6xg7u0lj5uv5jtglto/test_google_images_landslide_three.zip?rlkey=b7xnjid2s7zvfjbp0oqtji084&dl=0?raw=1\"\n",
    "\n",
    "test_dataset_url = 'https://dl.dropboxusercontent.com/s/0en4k86c1r1uzs0/test_google_images_landslides_four.zip?st=pdg6yhzj&dl=0?raw=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d93da1-57d2-4fca-adad-403a9b030d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_test = tf.keras.utils.get_file('test_google_images_landslides_four.zip', origin=test_dataset_url, extract=True)\n",
    "data_dir_test = pathlib.Path(data_dir_test).with_suffix('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82133bd4-f718-4536-9e2a-e09ee5f53c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Review folders in incoming data / classes\n",
    "folders = [folder for folder in data_dir_test.glob('*') if folder.is_dir()]\n",
    "print(\"Folders in the test directory:\")\n",
    "for folder in folders:\n",
    "    print(folder.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab8099-8789-47f6-924b-f7bd8846076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drill into each subdirectory and list files\n",
    "for folder in folders:\n",
    "    print(f\"\\nContents of folder '{folder.name}':\")\n",
    "    for subitem in folder.iterdir():\n",
    "        if subitem.is_file():\n",
    "            print(f\"  File: {subitem.name}\")\n",
    "        elif subitem.is_dir():\n",
    "            print(f\"  Subfolder: {subitem.name}\")\n",
    "            count = len(list(subitem.glob('*.jpg')))\n",
    "            print(f\"{subitem.name}: {count} .jpg images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd84d5-1610-418e-af82-472bc487caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Review an image\n",
    "test_one = list(data_dir_test.glob('Google_Earth_Images/landslides/*'))\n",
    "# PIL.Image.open(str(test_one[2]))\n",
    "resize_show(test_one[25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c1de6b-6a28-461b-a7c2-e2cb5fbc73af",
   "metadata": {},
   "source": [
    "## **Create the model dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ff64e-8146-49ee-88ab-85e46611e819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Add new Import package to chunk above.  \n",
    "## from collections import Counter\n",
    "## from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd589e-8bbe-4032-85e8-e1a9fa6ee7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Set Batch and Image size. \n",
    "batch_size = 32\n",
    "img_height = 300\n",
    "img_width = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67666d00-9c2a-4e53-a766-ed985bc4cbc6",
   "metadata": {},
   "source": [
    "#### Create Training / Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40e604-c282-455c-bcce-bb5c8b784a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Set Training Set image set. \n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.20,\n",
    "  subset=\"training\",\n",
    "  seed=512,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc35ae-b9af-4a4f-b9b2-4bbb6395bda1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setup Valiation set.\n",
    "valid_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.20,\n",
    "  subset=\"validation\",\n",
    "  seed=512,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213dfd32-dca7-4aef-9d8e-a817c190087e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the total samples in training and validation sets\n",
    "train_count = sum(1 for _ in train_dataset.unbatch())\n",
    "valid_count = sum(1 for _ in valid_dataset.unbatch())\n",
    "\n",
    "# Initialize class counters\n",
    "train_class_counts = {}\n",
    "valid_class_counts = {}\n",
    "\n",
    "# Function to count samples per class\n",
    "def count_classes(dataset, class_counts):\n",
    "    for _, labels in dataset.unbatch():\n",
    "        label = int(labels.numpy())\n",
    "        if label not in class_counts:\n",
    "            class_counts[label] = 0\n",
    "        class_counts[label] += 1\n",
    "\n",
    "# Count samples in training and validation datasets\n",
    "count_classes(train_dataset, train_class_counts)\n",
    "count_classes(valid_dataset, valid_class_counts)\n",
    "\n",
    "# Display counts\n",
    "print(f\"Training set size: {train_count}\")\n",
    "print(f\"Validation set size: {valid_count}\")\n",
    "print(\"\\nClass distribution in Training set:\")\n",
    "for class_label, count in sorted(train_class_counts.items()):\n",
    "    print(f\"  Class {class_label}: {count} samples\")\n",
    "\n",
    "print(\"\\nClass distribution in Validation set:\")\n",
    "for class_label, count in sorted(valid_class_counts.items()):\n",
    "    print(f\"  Class {class_label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921fd5d-3022-429f-95f2-ef565e6ddf20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Checking Images and Labels:\n",
    "plt.figure(figsize=(10, 5))\n",
    "for images, labels in train_dataset.take(1):  # Take one batch\n",
    "    for i in range(8):  # Display first 6 samples\n",
    "        ax = plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        label = labels[i].numpy()\n",
    "        label_name = class_names[label] if 'class_names' in locals() else label\n",
    "        plt.title(f\"Label: {label} ({label_name})\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf210542-4ff8-447a-9226-feec4e1c72a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"border:8px solid #0a0849\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b7d82-a502-4ade-a743-5b452186dc45",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Class Weights for use during Model Fit**\n",
    "- Added code to create Class Weights (class_weight=class_weight,) that you may use during the Model Fit process. \n",
    "- https://keras.io/examples/structured_data/imbalanced_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c025ad3-cb1f-48f9-b348-4ee85df4e16f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming `train_dataset` is your dataset and you have class labels as `y_train`\n",
    "class_labels = np.concatenate([y.numpy() for _, y in train_dataset])\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',  # Option to use 'balanced' or specify manual weights\n",
    "    classes=np.unique(class_labels),\n",
    "    y=class_labels\n",
    ")\n",
    "\n",
    "# Convert to a dictionary (Keras expects this format)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class weights:\", class_weights_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.13.0",
   "language": "python",
   "name": "tensorflow-2.13.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
