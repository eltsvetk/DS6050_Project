{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a40b050-4c26-405f-beae-73368d67b5d6",
   "metadata": {},
   "source": [
    "<span style=\"color:#b01604;font-weight:700;font-size:30px\"> \n",
    "Phase II: EfficientNetB3 Fine-Tuning (Sets 1-3)\n",
    "</span> <br>\n",
    "\n",
    "**Harold Haugen** <br>\n",
    "Early fine-tuning experiments with progressive layer unfreezing (10-45 layers) on preliminary datasets<br>\n",
    "<span style=\"background-color:#f0f0f0;color:#333;font-size:15px;font-weight:700;padding:10px;display:inline-block;margin-top:10px;border:2px solid #666;\">\n",
    "ARCHIVE NOTE: See \"Model_SecondPhase_EFB3_hh-combdata\" for full documentation with Training / Validation Set 4\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52cef317-9cb2-4ee0-ba51-32ef75df0dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 13:47:20.620017: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-11 13:47:22.171618: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-11 13:47:22.527457: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-11 13:47:22.714843: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 13:47:23.632159: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers   ### Adding 'regularizers'\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "import pathlib\n",
    "# import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76818bbc-2f69-40ef-957d-3c21cbf22c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53575f6-e76d-416e-9061-b7d93eb237dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<span style=\"color:#180842; font-size:26px\">\n",
    "Train/Validation Data Pull\n",
    "</span>** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324d5f9-5ada-4b9d-8c87-7b94c724d46a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the path to the zip file\n",
    "# dataset_url = \"https://dl.dropboxusercontent.com/scl/fi/hgz1prxm1kx14w5riy9du/ls_model_data_three.zip?rlkey=7cv22qxmmaeofr7jn6z7iayjy&dl=0?raw=1\"\n",
    "# dataset_url = \"https://dl.dropboxusercontent.com/scl/fi/vmox93cwsx2vzrish3l63/land_ls_model_data_four.zip?rlkey=6uykz7bb0aoqbl8hgfkpt1t4f&dl=0?raw=1\"\n",
    "dataset_url = \"https://dl.dropboxusercontent.com/scl/fi/mrsbiu74dh3h3i0j2xi8b/ls_model_data_five.zip?rlkey=in4z2twssi71adfi1exknm67w&dl=0?raw=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758e88c-6c41-4fd4-a6cc-3043c4fa3692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file('ls_model_data_five.zip', origin=dataset_url, extract=True)\n",
    "data_dir = pathlib.Path(data_dir).with_suffix('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f45a5-23a0-40fd-a803-c381f639f624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49c01e6-57f8-43f9-bb61-abb57b9e813c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drill into each subdirectory and list counts per folder\n",
    "folders = [folder for folder in data_dir.glob('*') if folder.is_dir()]\n",
    "for folder in folders:\n",
    "    print(f\"\\nContents of folder '{folder.name}':\")\n",
    "    # for subitem in folder.iterdir():\n",
    "    count = len(list(folder.glob('*.jpg')))\n",
    "    print(f\"{folder.name}: {count} .jpg images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb497ce8-e9dc-4783-a884-7127007d2519",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<span style=\"color:#180842; font-size:26px\">\n",
    "Test Data Pull\n",
    "</span>** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee162e05-1892-45c1-a808-f42549f4046d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://www.dropbox.com/scl/fi/nyv6xg7u0lj5uv5jtglto/test_google_images_landslide_three.zip?rlkey=b7xnjid2s7zvfjbp0oqtji084&dl=0\n",
    "# test_dataset_url = \"https://dl.dropboxusercontent.com/scl/fi/nyv6xg7u0lj5uv5jtglto/test_google_images_landslide_three.zip?rlkey=b7xnjid2s7zvfjbp0oqtji084&dl=0?raw=1\"\n",
    "# test_dataset_url = \"https://dl.dropboxusercontent.com/s/0en4k86c1r1uzs0/test_google_images_landslides_four.zip?st=pdg6yhzj&dl=0?raw=1\"\n",
    "# test_dataset_url = \"https://dl.dropboxusercontent.com/scl/fi/kl3e9wxoibqu0ldogwxg0/test_google_images_landslides_five.zip?rlkey=zuhh6xvjy3oi9wuroy4ogtdi3&dl=0?raw=1\"\n",
    "test_dataset_url = \"https://dl.dropboxusercontent.com/scl/fi/a8evtoop10e9cadnxorqw/google_earth_unique_test.zip?rlkey=g463zbw32hn5ez80wb1qogw4g&dl=0?raw=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef8163f-e096-4bf0-b9f2-94d171821cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_test = tf.keras.utils.get_file('google_earth_unique_test.zip', origin=test_dataset_url, extract=True)\n",
    "data_dir_test = pathlib.Path(data_dir_test).with_suffix('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac98c4-7bbf-4708-939d-9f5deea5e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Review folders in incoming data / classes\n",
    "folders_test = [folder for folder in data_dir_test.glob('*') if folder.is_dir()]\n",
    "print(\"Folders in the test directory:\")\n",
    "for folder in folders_test:\n",
    "    print(folder.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673526f6-6785-42fe-b5f0-25db14d41675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drill into each subdirectory and list counts per folder\n",
    "folders = [folder for folder in data_dir_test.glob('*') if folder.is_dir()]\n",
    "for folder in folders:\n",
    "    print(f\"\\nContents of folder '{folder.name}':\")\n",
    "    # for subitem in folder.iterdir():\n",
    "    count = len(list(folder.glob('*.jpg')))\n",
    "    print(f\"{folder.name}: {count} .jpg images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb12671-49df-49c5-ac6f-2ba0a482a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drill into each subdirectory and list files\n",
    "# total_files = 0\n",
    "# for folder in folders_test:\n",
    "#     print(f\"\\nContents of folder '{folder.name}':\")\n",
    "#     for subitem in folder.iterdir():\n",
    "#         if subitem.is_file():\n",
    "#             print(f\"  File: {subitem.name}\")\n",
    "#         elif subitem.is_dir():\n",
    "#             print(f\"  Subfolder: {subitem.name}\")\n",
    "#             count = len(list(subitem.glob('*.jpg')))\n",
    "#             print(f\"{subitem.name}: {count} .jpg images\")\n",
    "#             total_files += count  # Add the count of .jpg images to the total\n",
    "            \n",
    "# # Print the total number of files\n",
    "# print(f\"\\nTotal number of files: {total_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b6fc6b-cc96-4120-a3d7-f3a66fbb7ec6",
   "metadata": {},
   "source": [
    "**<span style=\"color:#180842; font-size:26px\">\n",
    "Set Training/Validation Data & Split\n",
    "</span>** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781e5eb-d33c-4ebc-abdf-46b7b258d6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Set Batch and Image size. \n",
    "batch_size = 32\n",
    "img_height = 300\n",
    "img_width = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f2597d-d105-4fa6-9bcd-e942ed584f43",
   "metadata": {},
   "source": [
    "#### Create Training / Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db40f6d-e533-429c-90d2-7218b6e55daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Set Training Set image set. \n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.20,\n",
    "  subset=\"training\",\n",
    "  seed=634,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd64b63-b50e-4d67-9ab6-f8394f6eafbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setup Valiation set.\n",
    "valid_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.20,\n",
    "  subset=\"validation\",\n",
    "  seed=634,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4472a4ce-b8b5-4e44-a679-6922cd2a4852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the total samples in training and validation sets\n",
    "train_count = sum(1 for _ in train_dataset.unbatch())\n",
    "valid_count = sum(1 for _ in valid_dataset.unbatch())\n",
    "\n",
    "# Initialize class counters\n",
    "train_class_counts = {}\n",
    "valid_class_counts = {}\n",
    "\n",
    "# Function to count samples per class\n",
    "def count_classes(dataset, class_counts):\n",
    "    for _, labels in dataset.unbatch():\n",
    "        label = int(labels.numpy())\n",
    "        if label not in class_counts:\n",
    "            class_counts[label] = 0\n",
    "        class_counts[label] += 1\n",
    "\n",
    "# Count samples in training and validation datasets\n",
    "count_classes(train_dataset, train_class_counts)\n",
    "count_classes(valid_dataset, valid_class_counts)\n",
    "\n",
    "# Display counts\n",
    "print(f\"Training set size: {train_count}\")\n",
    "print(f\"Validation set size: {valid_count}\")\n",
    "print(\"\\nClass distribution in Training set:\")\n",
    "for class_label, count in sorted(train_class_counts.items()):\n",
    "    print(f\"  Class {class_label}: {count} samples\")\n",
    "\n",
    "print(\"\\nClass distribution in Validation set:\")\n",
    "for class_label, count in sorted(valid_class_counts.items()):\n",
    "    print(f\"  Class {class_label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e60862-40af-4e60-bc95-f9c6fd61814a",
   "metadata": {},
   "source": [
    "### Buffering/Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0993ac05-9390-4d02-a21f-c0de84c30361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Data Performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.cache().shuffle(3200).prefetch(buffer_size=AUTOTUNE)\n",
    "valid_dataset = valid_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd82a15-acfb-41a1-844a-2d02dc778e62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Checking Images and Labels:\n",
    "plt.figure(figsize=(10, 5))\n",
    "for images, labels in train_dataset.take(1):  # Take one batch\n",
    "    for i in range(8):  # Display first 6 samples\n",
    "        ax = plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        label = labels[i].numpy()\n",
    "        label_name = class_names[label] if 'class_names' in locals() else label\n",
    "        plt.title(f\"Label: {label} ({label_name})\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6fa56e-b14c-40d1-905d-0bdf4f82583d",
   "metadata": {},
   "source": [
    "**<span style=\"color:#180842; font-size:26px\">\n",
    "Set Test Data\n",
    "</span>** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf52de-33e2-47d4-ba3e-61bceed8cec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Update path given the Google_Earth_Images/landslide vs. non-landslide directory structure. \n",
    "data_dir_test_lvltwo=pathlib.Path(data_dir_test) #/ 'Google_Earth_Images'\n",
    "data_dir_test_lvltwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365a525-148a-4003-bc47-71df2ea1a356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir_test_lvltwo,   # Base directory\n",
    "    labels='inferred',           # Automatically assign labels based on folder names\n",
    "    subset=None,                 # No split; we are directly specifying test data\n",
    "    seed=614,                    # Random seed for reproducibility\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,  ### Add because the labels and images were getting mixed up in processing. \n",
    "    validation_split=None,       # No validation split; test data only\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1742a-1e4e-4faa-a02a-ba8aad719f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Review class names based on dataset. \n",
    "class_names = test_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e9fc12-cb49-49a6-8455-22765ee095e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Checking the Labels. \n",
    "plt.figure(figsize=(12, 7))\n",
    "for images, labels in test_dataset.take(1):  # Take one batch\n",
    "    for i in range(18):  # Display first 6 samples\n",
    "        ax = plt.subplot(3, 6, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        label = labels[i].numpy()\n",
    "        label_name = class_names[label] if 'class_names' in locals() else label\n",
    "        plt.title(f\"Label: {label} ({label_name})\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7605bc73-2d67-4938-b111-9f4faa222180",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"border:8px solid #301b66\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c920e1a-057b-437d-9fb9-87631635eab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Class Weights for use during Model Fit**\n",
    "- Added code to create Class Weights (class_weight=class_weight,) that you may use during the Model Fit process. \n",
    "- https://keras.io/examples/structured_data/imbalanced_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6570dd0-4d23-4021-ac1a-00f7279836a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming `train_dataset` is your dataset and you have class labels as `y_train`\n",
    "class_labels = np.concatenate([y.numpy() for _, y in train_dataset])\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',  # Option to use 'balanced' or specify manual weights\n",
    "    classes=np.unique(class_labels),\n",
    "    y=class_labels\n",
    ")\n",
    "\n",
    "# Convert to a dictionary (Keras expects this format)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class weights:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b79ca-1999-4274-8d00-70e8c178b1b1",
   "metadata": {},
   "source": [
    "<hr style=\"border:8px solid #301b66\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c787777-ace8-4a24-ba77-ebe181b15a8d",
   "metadata": {},
   "source": [
    "**<span style=\"color:#0638b2; font-size:30px\">\n",
    "Model Design w/ Transfer Learning\n",
    "</span>** <br>\n",
    "\n",
    "\n",
    "Pre-Training with EfficientNet\n",
    "- Strengths: EfficientNet models scale well in terms of parameters and efficiency, balancing accuracy with computational cost, which is especially useful for large datasets.\n",
    "- Suitability: EfficientNet performs exceptionally well on high-resolution images, which is ideal for detecting fine details in satellite images.\n",
    "- https://viso.ai/deep-learning/efficientnet/\n",
    "- https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9237a5d1-0f06-46c8-9a1f-db0213c6b73b",
   "metadata": {},
   "source": [
    "**Setting up EfficientNet**\n",
    "- Note - using B3 as this is set up for 300x300 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080d80f-3ebe-4040-b077-8cd3955b0348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Import EFB3 Model Weights\n",
    "from tensorflow.keras.applications import EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca2932-1349-4fb3-ba3d-7667363599dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Calc. the number of classes. \n",
    "land_class_num = len(folders)\n",
    "land_class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6e144-0c8d-496e-bcd0-ccd9e2c951e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up parameters for model. \n",
    "IMG_SIZE = 300\n",
    "learn_rate_land = 1e-3  ## For optimizer.\n",
    "\n",
    "print(land_class_num) ## Check class number AND use as argument below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb52e28-d3dd-4f52-a544-f6067446393e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"border:3px solid #301b66\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f6ba19-2bf5-42f7-ad24-8bbbc6c37225",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4475448-ba3c-4531-9d91-5b18da1049b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Plot Helper\n",
    "def visualize_model_results(model_input):\n",
    "    acc = model_input.history['accuracy']\n",
    "    val_acc = model_input.history['val_accuracy']\n",
    "\n",
    "    loss = model_input.history['loss']\n",
    "    val_loss = model_input.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd26a2-06c6-4051-8dbd-5bc5fb565801",
   "metadata": {},
   "source": [
    "Saturation\n",
    "- The saturation factor is sampled randomly from a uniform distribution in the range [lower, upper].\n",
    "- A saturation factor of 1.0 means no change in saturation.\n",
    "- A saturation factor below 1.0 decreases the saturation (the image will appear less vibrant or more grayscale).\n",
    "- A saturation factor above 1.0 increases the saturation (the image will appear more vibrant)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5a6f1-fb2a-48ea-a44c-44e54c2ce3ca",
   "metadata": {},
   "source": [
    "#### **Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b5f374-7e68-4a81-b387-10b5b3d4408b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Data Augmentation Helper\n",
    "# data_augmentation = keras.Sequential(\n",
    "#   [\n",
    "#     keras.layers.RandomRotation(factor=0.10),\n",
    "#     keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "#     keras.layers.RandomFlip(\"horizontal\"),\n",
    "#     keras.layers.RandomContrast(factor=0.5),\n",
    "#     keras.layers.RandomBrightness(factor=.6),\n",
    "      \n",
    "#     # layers.RandomSaturation(.7, seed=516) ## Error\n",
    "#     keras.layers.Lambda(lambda x: tf.image.random_saturation(x, lower=0.3, upper=1.2))\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    # keras.layers.Input((350, 350, 3)),\n",
    "    keras.layers.RandomRotation(factor=0.40),\n",
    "    keras.layers.RandomTranslation(height_factor=0.4, width_factor=0.4, fill_mode=\"reflect\"),\n",
    "    keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    # keras.layers.RandomCrop(300, 300),\n",
    "    keras.layers.RandomContrast(factor=0.7), ## Values closer to 0 = minimal adjustment, higher to 1.0 allow larger contrast variations.\n",
    "    keras.layers.RandomBrightness(factor=.7),\n",
    "      \n",
    "    # layers.RandomSaturation(.7, seed=516) ## Error\n",
    "    keras.layers.Lambda(lambda x: tf.image.random_saturation(x, lower=0.7, upper=1.3))\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc0a66b-3f33-4b65-abb5-d37c2621a022",
   "metadata": {},
   "source": [
    "<hr style=\"border:3px solid #301b66\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1516a42e-1ad5-4bda-9033-c847fa26c949",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3460a67-07c2-44c9-93fe-170e4e5a40fa",
   "metadata": {},
   "source": [
    "### **Define Model Design**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7798a187-c7e8-401c-8e2f-902b7056908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model EfficientNetB3.\n",
    "def build_model(num_classes, learning_r):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "       \n",
    "    ### Adding Augmentation\n",
    "    augmented_inputs = data_augmentation(inputs)  ## Added Line\n",
    "    \n",
    "    ### Add a rescaling layer to normalize pixel values to range [0, 1] !! Note-this caused a large decrease in performance...\n",
    "    # normalized_inputs = Rescaling(scale=1.0 / 255)(augmented_inputs)\n",
    "    \n",
    "    model = EfficientNetB3(include_top=False, input_tensor=augmented_inputs, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.20\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "    # outputs = layers.Dense(1, activation=\"sigmoid\", name=\"pred\")(x) ## Use for Binary Cross Entropy\n",
    "\n",
    "    # Compile\n",
    "    model = keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_r)  ## originally 1e-2\n",
    "    model.compile(\n",
    "        # optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        # optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0fe867-7f05-4bca-9aed-e425d7696c28",
   "metadata": {},
   "source": [
    "### **Build Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f737f3-17ab-43e9-97e8-97d78c245923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up parameters for model. \n",
    "IMG_SIZE = 300\n",
    "learn_rate_land = 1e-4  ## For optimizer.\n",
    "\n",
    "print(land_class_num) ## Check class number AND use as argument below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e4e9b-b127-44fd-9228-2fbcf6ec8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Model\n",
    "landslide_model_ENB3 = build_model(num_classes=land_class_num, learning_r=learn_rate_land)\n",
    "# landslide_model_ENB3 = build_model(num_classes=1) ## for when we use Sigmoid/Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee4910-1c91-433d-b84d-9b800916dd61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Review of the model structure:   Confirm that no layers are open after set.\n",
    "# landslide_model_ENB3.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183fe9d4-b1dc-4bb3-a9e5-e4ef93f3dc1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b005a3c-a12a-4e6b-9ef3-eb2d84837722",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15  # @param {type: \"slider\", min:8, max:80}\n",
    "landslide_ENB3_hist = landslide_model_ENB3.fit(train_dataset, epochs=epochs, validation_data=valid_dataset, class_weight=class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ad5b4-6100-415b-883c-d0db5456827b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot results\n",
    "visualize_model_results(landslide_ENB3_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd385652-e97c-4e3e-b8cd-befe5cc6bf13",
   "metadata": {},
   "source": [
    "### **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615828c0-c4a6-41b1-a478-6fe6b328fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test landslide images\")\n",
    "results = landslide_model_ENB3.evaluate(test_dataset)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c8dbe-b549-4c80-9b25-282505e73424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get predictions and true labels\n",
    "y_pred_probs = landslide_model_ENB3.predict(test_dataset)  # Predict probabilities\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Get the class with the highest probability\n",
    "y_true = np.concatenate([y for x, y in test_dataset], axis=0)  # Extract true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b0045-0369-46bc-b6b1-05c930a10183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Predict probabilities when using a Binary Optimizer (sigmoid output)\n",
    "\n",
    "# y_pred_probs = landslide_model_ENB3.predict(test_dataset)  # Predict probabilities\n",
    "\n",
    "# # Convert probabilities to binary predictions (threshold at 0.5)\n",
    "# y_pred = (y_pred_probs > 0.5).astype(int).flatten()  # Convert to binary class (0 or 1)\n",
    "\n",
    "# # Extract true labels from the dataset\n",
    "# y_true = np.concatenate([y for x, y in test_dataset], axis=0)  # True labels\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Predicted probabilities: {y_pred_probs[:5]}\")\n",
    "# print(f\"Binary predictions: {y_pred[:5]}\")\n",
    "# print(f\"True labels: {y_true[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc384526-2ff0-40e5-9bb4-8300b4ab91fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_dataset.class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9091b-36a1-4ede-b99c-5bdc348f8d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Extract TP, TN, FP, FN - HH - Redesigned to make Landslides the TPs\n",
    "# TN, FP, FN, TP = cm.ravel()\n",
    "TP, FN, FP, TN = cm.ravel()\n",
    "\n",
    "print(f\"True Positives (TP): {TP}  False Negatives (FN): {FN}\")\n",
    "print(f\"False Positives (FP): {FP} True Negatives (TN): {TN}\")\n",
    "print('\\n')\n",
    "print(f'Accuracy: {round((TP+TN)/(TP+TN+FP+FN),3)}')\n",
    "precision_val = round(TP/(TP+FP),3); #print(precision_val)\n",
    "print(f'Precision: TP / (TP + FP) | Positive predictions are correct. {precision_val}')\n",
    "recall_val = round(TP/(TP+FN),3); #print(recall_val)\n",
    "print(f'Recall: TP / (TP + FN) | Actual positive cases that are identified. {recall_val}')\n",
    "specificity_val = round(TN/(TN+FP),3);\n",
    "print(f'Specificity: TN / (TN + FP) | Actual negative cases that are identified. {specificity_val}')\n",
    "\n",
    "F1_val = round(2*(precision_val*recall_val)/(precision_val+recall_val),3);  #print(F1_val)\n",
    "print(f'F1 Score: 2 * (Precision * Recall) / (Precision + Recall) | Balance Measurement. {F1_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f88d1a-2e59-40a6-8760-9f4e24348c78",
   "metadata": {},
   "source": [
    "### Identify Image File to Prediction|True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652fd5b-efa7-4501-9bcb-d60367cd85a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_paths = test_dataset.file_paths  # This retrieves file paths corresponding to each sample\n",
    "\n",
    "# Get predictions\n",
    "y_pred_probs = landslide_model_ENB3.predict(test_dataset)  # Predict probabilities\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Predicted class\n",
    "\n",
    "# Extract true labels\n",
    "y_true = np.concatenate([y for _, y in test_dataset], axis=0)\n",
    "\n",
    "# Map file paths to predictions\n",
    "file_class_map = zip(file_paths, y_pred, y_true)  # Zip paths, predictions, and true labels\n",
    "\n",
    "print(\"\\nImages with predicted and true labels:\")\n",
    "for file_path, pred, true in file_class_map:\n",
    "    if pred != true & true == 0:    ## Added to only see where prediction is INCORRECT...\n",
    "        print(f\"File: {file_path}, Predicted: {pred}, True Label: {true}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac6713-35c4-4fe3-ae08-74f43760bd8a",
   "metadata": {},
   "source": [
    "<hr style=\"border:15px solid #301b66\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e4cb34-2f39-4a3b-81f1-6a8d0066d81a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<span style=\"color:#0638b2; font-size:30px\">\n",
    "Fine Tuning - Opening Up Feature Layers\n",
    "</span>** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbcca02-518f-4219-9102-c9c3e306e095",
   "metadata": {},
   "source": [
    "### **Number of Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d58fa-5b3e-4ce6-be82-78332047a748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze all layers\n",
    "for layer in landslide_model_ENB3.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96510373-3fcd-4acf-aa03-b80ca4d55584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Number of Layers to Open!!!\n",
    "layer_open = 12\n",
    "layer_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb094044-4d74-47c3-aa26-f05048e64730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Update Model\n",
    "def unfreeze_model(model, layer_num):   \n",
    "    # We unfreeze the top XXX layers while leaving BatchNorm layers frozen\n",
    "    for layer in model.layers[-layer_num:]:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"] )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53b4ff-f009-45ac-bb7c-c3245458026a",
   "metadata": {},
   "source": [
    "<hr style=\"border:3px solid #301b66\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e86ee1-95c5-48e2-bac1-acec4ef46ad0",
   "metadata": {},
   "source": [
    "### **Rebuild**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de50c75-a847-4138-9a44-9a997f23d2aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Rebuild model with XX Layers open for Fine Tuning.\n",
    "unfreeze_model(landslide_model_ENB3, layer_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce299f78-bc5f-46d3-9f75-79db12addf31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Review of the model structure:   Confirm that no layers are open after set.\n",
    "# landslide_model_ENB3.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7045f4-e74a-4ad1-8e3f-51258e07e350",
   "metadata": {},
   "source": [
    "## **Fit Model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f005724-34f6-41aa-a4f0-e9b22f5c1473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unfreeze_model(landslide_model_ENB3, layer_open)\n",
    "\n",
    "# epochs = 10  # @param {type: \"slider\", min:4, max:10}\n",
    "# EFB3_hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n",
    "# plot_hist(hist)\n",
    "\n",
    "epochs = 10  # @param {type: \"slider\", min:8, max:80}\n",
    "ENB3_hist_fine = landslide_model_ENB3.fit(train_dataset, epochs=epochs, validation_data=valid_dataset, \n",
    "                                          class_weight=class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7c0de-d52a-42b1-a808-ffa482be7655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot results\n",
    "visualize_model_results(ENB3_hist_fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222e94f-99f6-42fc-93aa-0ec0cf10c323",
   "metadata": {},
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f8290-37df-4055-947d-b20a53ce02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test landslide images\")\n",
    "results = landslide_model_ENB3.evaluate(test_dataset)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d5498-3ca6-4e99-87f2-8e1289cba7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and true labels\n",
    "y_pred_probs = landslide_model_ENB3.predict(test_dataset)  # Predict probabilities\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Get the class with the highest probability\n",
    "y_true = np.concatenate([y for x, y in test_dataset], axis=0)  # Extract true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143a37f-32a3-45e5-b5ab-2756a5dbf388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Confusion Matrix\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_dataset.class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a48a18-8350-48cb-a289-978e5e73d2a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Extract TP, TN, FP, FN - HH - Redesigned to make Landslides the TPs\n",
    "# TN, FP, FN, TP = cm.ravel()\n",
    "TP, FN, FP, TN = cm.ravel()\n",
    "\n",
    "print(f\"True Positives (TP): {TP}  False Negatives (FN): {FN}\")\n",
    "print(f\"False Positives (FP): {FP} True Negatives (TN): {TN}\")\n",
    "print('\\n')\n",
    "print(f'Accuracy: {round((TP+TN)/(TP+TN+FP+FN),3)}')\n",
    "precision_val = round(TP/(TP+FP),3); #print(precision_val)\n",
    "print(f'Precision: TP / (TP + FP) | Positive predictions are correct. {precision_val}')\n",
    "recall_val = round(TP/(TP+FN),3); #print(recall_val)\n",
    "print(f'Recall: TP / (TP + FN) | Actual positive cases that are identified. {recall_val}')\n",
    "specificity_val = round(TN/(TN+FP),3);\n",
    "print(f'Specificity: TN / (TN + FP) | Actual negative cases that are identified. {specificity_val}')\n",
    "\n",
    "F1_val = round(2*(precision_val*recall_val)/(precision_val+recall_val),3);  #print(F1_val)\n",
    "print(f'F1 Score: 2 * (Precision * Recall) / (Precision + Recall) | Balance Measurement. {F1_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc543a4-024b-44c0-ace3-94039242ac0b",
   "metadata": {},
   "source": [
    "### Identify Image File to Prediction|True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8096f-f70e-4d84-a8ff-438caaf8672b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_paths = test_dataset.file_paths  # This retrieves file paths corresponding to each sample\n",
    "\n",
    "# Get predictions\n",
    "y_pred_probs = landslide_model_ENB3.predict(test_dataset)  # Predict probabilities\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Predicted class\n",
    "\n",
    "# Extract true labels\n",
    "y_true = np.concatenate([y for _, y in test_dataset], axis=0)\n",
    "\n",
    "# Map file paths to predictions\n",
    "file_class_map = zip(file_paths, y_pred, y_true)  # Zip paths, predictions, and true labels\n",
    "\n",
    "print(\"\\nImages with predicted and true labels:\")\n",
    "for file_path, pred, true in file_class_map:\n",
    "    if pred != true & true == 0:    ## Added to only see where prediction is INCORRECT...\n",
    "        print(f\"File: {file_path}, Predicted: {pred}, True Label: {true}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3b4c600-d18d-4268-bde5-8976dc442ce0",
   "metadata": {
    "tags": []
   },
   "source": [
    "landslide_model_ENB3.summary(show_trainable=True)\n",
    "# model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b2a2028-6908-40ab-b14a-7b7a7e9c9c1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model before opening up layers \n",
    "landslide_model_ENB3.summary(show_trainable=True)\n",
    "# model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf105dc-e5aa-4545-a1cb-9f173fcce597",
   "metadata": {},
   "source": [
    "<hr style=\"border:8px solid #301b66\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23048d-6e7c-4019-ac45-2cedbc6ca7d0",
   "metadata": {},
   "source": [
    "**<span style=\"color:#0638b2; font-size:30px\">\n",
    "Train Model on Full Population\n",
    "</span>** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d6294-5739-4f15-b446-59c826f5c1df",
   "metadata": {},
   "source": [
    "<hr style=\"border:8px solid #301b66\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf8348-8742-413b-9a48-c7d76087d025",
   "metadata": {},
   "source": [
    "**<span style=\"color:#0638b2; font-size:30px\">\n",
    "Saving Model for Future Use\n",
    "</span>** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8bfad6-cf82-490d-8e14-a36fd36e3f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calling `save('my_model.keras')` creates a zip archive `my_model.keras`.\n",
    "# model.save(\"my_model.keras\")\n",
    "landslide_model_ENB3.save(\"/sfs/gpfs/tardis/home/waa4bq/Documents/MSDS/6050 Deep Learning/DS6050_Project/ENB3_One_40Lyr_hh.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba564d81-f268-43b9-adde-d7e814017a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
